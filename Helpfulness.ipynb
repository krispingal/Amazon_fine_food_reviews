{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Amazon Fine Food Reviews - Helpfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "#import nltk\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Import data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect('./input/database.sqlite')\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "SELECT Id, UserId, HelpfulnessNumerator, HelpfulnessDenominator, Score, Summary, Text, Time\n",
    "FROM Reviews where HelpfulnessDenominator > 10\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'], unit='s')\n",
    "df['WordCount'] = map(lambda x: len(x.split()), df['Text'])\n",
    "df['CharCount'] = map(lambda x: len(x), df['Text'])\n",
    "df['SentenceCount'] = map(lambda x: len(x.splitlines()), df['Text'])\n",
    "df['ARI'] = 4.71 * (df['CharCount'].astype(float) / df['WordCount']) + 0.5 * (df['WordCount'].astype(float) / df['SentenceCount']) - 21.43\n",
    "df['Year'] = pd.DatetimeIndex(df['Time']).year\n",
    "df['Month'] = pd.DatetimeIndex(df['Time']).month\n",
    "le = LabelEncoder()\n",
    "df['UserId_le'] = le.fit_transform(df['UserId'])\n",
    "df['HelpfulnessDenominator'].fillna(0, inplace=True)\n",
    "df['HelpfulnessNumerator'].fillna(0, inplace=True)\n",
    "df['HelpfulnessRatio'] = np.divide(df['HelpfulnessNumerator'].astype(float), df['HelpfulnessDenominator'])\n",
    "df['HelpfulnessRatio'].fillna(0, inplace=True)\n",
    "df.drop('HelpfulnessNumerator', axis=1, inplace=True)\n",
    "df['HelpfulnessRatio'] = [1 if x > 1.0 else x for x in  df['HelpfulnessRatio']]\n",
    "df['HelpfulnessLabel'] = np.where(df['HelpfulnessRatio'] > 0.8, 1, 0) \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Id', 'UserId_le', 'HelpfulnessDenominator', 'Score', 'WordCount', 'CharCount', 'SentenceCount', 'ARI']], df['HelpfulnessLabel'], test_size=0.2, random_state=432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79594689,  0.79437456,  0.79762321])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "#perform feature scaling to be more effective \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "clf = SGDClassifier(n_iter = 25)\n",
    "cross_val_score(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 404.00 seconds for 24 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.801 (std: 0.001)\n",
      "Parameters: {'n_iter': 10, 'eta0': 0.001, 'loss': 'hinge', 'average': True, 'penalty': 'elasticnet', 'random_state': 43, 'alpha': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.801 (std: 0.001)\n",
      "Parameters: {'n_iter': 10, 'eta0': 0.10000000000000001, 'loss': 'hinge', 'average': True, 'penalty': 'l1', 'random_state': 43, 'alpha': 0.0001, 'learning_rate': 'invscaling'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.801 (std: 0.001)\n",
      "Parameters: {'n_iter': 10, 'eta0': 0.10000000000000001, 'loss': 'hinge', 'average': False, 'penalty': 'elasticnet', 'random_state': 43, 'alpha': 9.9999999999999995e-07, 'learning_rate': 'invscaling'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'loss' : ['hinge', 'epsilon_insensitive', 'squared_hinge'],\n",
    "    'penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate' : ['constant', 'optimal', 'invscaling'],\n",
    "    'alpha' : 10.0**-np.arange(1,7),\n",
    "    'n_iter' : [10, 25, 30],\n",
    "    'average' : [True, False],\n",
    "    'eta0' : 10.0**-np.arange(1,4),\n",
    "    'random_state' : [43]\n",
    "}\n",
    "clf = SGDClassifier()\n",
    "grid_search = GridSearchCV(clf, param_grid, n_jobs=-1)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_)))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test Error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79361751688795712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "grid_search.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
